{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches, patheffects\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from collections import namedtuple, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from session import *\n",
    "from LR_Schedule.cos_anneal import CosAnneal\n",
    "from LR_Schedule.lr_find import lr_find\n",
    "from callbacks import *\n",
    "from validation import *\n",
    "import Datasets.ImageClassifierData as ImageClassifierData\n",
    "from Transforms.ImageTransforms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 'GeForce GTX 960M', True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available(), torch.cuda.get_device_name(0), torch.backends.cudnn.enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(fn):\n",
    "    \"\"\" Opens an image using OpenCV given the file path.\n",
    "\n",
    "    Arguments:\n",
    "        fn: the file path of the image\n",
    "\n",
    "    Returns:\n",
    "        The image in RGB format as numpy array of floats normalized to range between 0.0 - 1.0\n",
    "    \"\"\"\n",
    "    flags = cv2.IMREAD_UNCHANGED+cv2.IMREAD_ANYDEPTH+cv2.IMREAD_ANYCOLOR\n",
    "    if not os.path.exists(fn) and not str(fn).startswith(\"http\"):\n",
    "        raise OSError('No such file or directory: {}'.format(fn))\n",
    "    elif os.path.isdir(fn) and not str(fn).startswith(\"http\"):\n",
    "        raise OSError('Is a directory: {}'.format(fn))\n",
    "    else:\n",
    "        #res = np.array(Image.open(fn), dtype=np.float32)/255\n",
    "        #if len(res.shape)==2: res = np.repeat(res[...,None],3,2)\n",
    "        #return res\n",
    "        try:\n",
    "            if str(fn).startswith(\"http\"):\n",
    "                req = urllib.urlopen(str(fn))\n",
    "                image = np.asarray(bytearray(req.read()), dtype=\"uint8\")\n",
    "                im = cv2.imdecode(image, flags).astype(np.float32)/255\n",
    "            else:\n",
    "                im = cv2.imread(str(fn), flags).astype(np.float32)/255\n",
    "            if im is None: raise OSError(f'File not recognized by opencv: {fn}')\n",
    "            return cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        except Exception as e:\n",
    "            raise OSError('Error handling image at: {}'.format(fn)) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rect(ax, b):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor='white', lw=2))\n",
    "    draw_outline(patch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(ax, xy, txt, sz=14):\n",
    "    text = ax.text(*xy, txt,\n",
    "        verticalalignment='top', color='white', fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbtohw(a): \n",
    "    \"\"\"Bounding box to Height width.\n",
    "\n",
    "    Args:\n",
    "        param1 (arr): [xmin, ymin, xmax, ymax] where (xmin, ymin) \n",
    "            and (xmax, ymax) represent the top left and bottom \n",
    "            right corners of the bounding box\n",
    "\n",
    "    Returns:\n",
    "        arr: [xmin, ymin, width, height]\n",
    "\n",
    "    \"\"\"\n",
    "    return [a[0],a[1],a[2]-a[0],a[3]-a[1]]\n",
    "\n",
    "assert bbtohw([2, 5, 10, 20]) == [2, 5, 8, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('C:/fastai/courses/dl2/data/road_damage_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(df, group):\n",
    "    data = namedtuple('data', ['filename', 'object'])\n",
    "    gb = df.groupby(group)\n",
    "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = pd.read_csv(DATA_PATH/'train_labels.csv')\n",
    "images = split(examples, 'filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(example, ax=None):\n",
    "    im = open_image(DATA_PATH/example.filename)\n",
    "    if ax is not None:\n",
    "        show_img(im, ax=ax)\n",
    "    else:\n",
    "        ax = show_img(im)\n",
    "    for index, row in example.object.iterrows():\n",
    "        bb = bbtohw([row['xmin'], row['ymin'], row['xmax'], row['ymax']]) # Bounding box converted to height width\n",
    "        draw_rect(ax, bb)\n",
    "        draw_text(ax, bb[:2], row['class']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_example(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = open_image(DATA_PATH/images[1].filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flip = RandomHorizontalFlip()\n",
    "crop = RandomCrop(300)\n",
    "lighting = RandomLighting(0.5, 0.5)\n",
    "scale = RandomScale(600, (0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#show_img(im)\n",
    "#show_img(flip(im, 0)[0])\n",
    "#show_img(crop(im, 0)[0])\n",
    "#show_img(lighting(im, 0)[0])\n",
    "#show_img(scale(im, 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTICLASS_CSV_PATH = DATA_PATH/'mc.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmc = [set([row['class'] for index, row in img.object.iterrows()]) for img in images]\\nmcs = [' '.join(label for label in labels) for labels in mc]\\nprint(mc[0:4])\\nprint(mcs[0:4])\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mc = [set([row['class'] for index, row in img.object.iterrows()]) for img in images]\n",
    "mcs = [' '.join(label for label in labels) for labels in mc]\n",
    "print(mc[0:4])\n",
    "print(mcs[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'filename': [img.filename for img in images], 'class': mcs}, columns=['filename','class'])\n",
    "df.to_csv(MULTICLASS_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTIBB_CSV_PATH = DATA_PATH/'bb.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      filename  width  height class  xmin  \\\n",
      "9382  Adachi/JPEGImages/train_Adachi_00001.jpg    600     600   D44   424   \n",
      "9383  Adachi/JPEGImages/train_Adachi_00001.jpg    600     600   D10   114   \n",
      "\n",
      "      ymin  xmax  ymax  \n",
      "9382   361   590   546  \n",
      "9383   432   487   543  \n"
     ]
    }
   ],
   "source": [
    "print(images[0].object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbb = [np.concatenate([[row['xmin'], row['ymin'], row['xmax'], row['ymax']] for index, row in img.object.iterrows()]) for img in images]\n",
    "mbbs = [' '.join(str(p) for p in o) for o in mbb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mbbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'filename': [img.filename for img in images], 'bbox': mbbs}, columns=['filename','bbox'])\n",
    "df.to_csv(MULTIBB_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>bbox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adachi/JPEGImages/train_Adachi_00001.jpg</td>\n",
       "      <td>424 361 590 546 114 432 487 543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adachi/JPEGImages/train_Adachi_00002.jpg</td>\n",
       "      <td>113 353 260 592 318 300 455 582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adachi/JPEGImages/train_Adachi_00003.jpg</td>\n",
       "      <td>474 344 598 493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adachi/JPEGImages/train_Adachi_00004.jpg</td>\n",
       "      <td>362 228 524 578 130 310 399 589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adachi/JPEGImages/train_Adachi_00006.jpg</td>\n",
       "      <td>88 381 167 455 84 282 326 336 272 356 485 537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  \\\n",
       "0  Adachi/JPEGImages/train_Adachi_00001.jpg   \n",
       "1  Adachi/JPEGImages/train_Adachi_00002.jpg   \n",
       "2  Adachi/JPEGImages/train_Adachi_00003.jpg   \n",
       "3  Adachi/JPEGImages/train_Adachi_00004.jpg   \n",
       "4  Adachi/JPEGImages/train_Adachi_00006.jpg   \n",
       "\n",
       "                                            bbox  \n",
       "0                424 361 590 546 114 432 487 543  \n",
       "1                113 353 260 592 318 300 455 582  \n",
       "2                                474 344 598 493  \n",
       "3                362 228 524 578 130 310 399 589  \n",
       "4  88 381 167 455 84 282 326 336 272 356 485 537  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastAI custom",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
